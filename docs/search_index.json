[["infer.html", "8 Inferenzstatistik 8.1 Inferenz: von der Stichprobe zur allgemeinen Aussage 8.2 Hypothesentests 8.3 Mittelwertvergleiche mit dem t-Test 8.4 Übersicht zu Varianten für ttest 8.5 Gewichtung in Stata 8.6 Übungen 6 8.7 Anhang", " 8 Inferenzstatistik 8.1 Inferenz: von der Stichprobe zur allgemeinen Aussage Bisher haben wir die Angaben aus unserem Datensatz immer als fix angesehen. Ziel einer statistischen Auswertung ist aber meistens, Aussagen über die Grundgesamtheit oder Population zu treffen. Im Fall der ETB 2018 wären das also alle Erwerbstätigen in Deutschland. In der ETB 2018 wurde eine Zufallsstichprobe erhoben, um eine repräsentative Datengrundlage zu schaffen. Das heißt, es wurde ein Verfahren gewählt, das potenziell allen Erwerbstätigen die gleiche Chance gibt, in der Befragung zu landen. Damit ist unser Datensatz eine verkleinerter Ausschnitt aus der großen Gesamtpopulation, die wir dann für Aussagen über eben diese Gesamtpopulation verwenden können. Wenn wir uns jetzt beispielsweise das Durchschnittsalter in der Erwerbstätigenbefragung ansehen: summarize zpalter Variable | Obs Mean Std. Dev. Min Max -------------+--------------------------------------------------------- zpalter | 19,836 47.19228 11.33762 15 87 Natürlich ist relativ intuitiv, dass das Durchschnittsalter aller Erwerbstätigen in Deutschland nicht exakt 47.19228 betragen wird. Wir wären uns aber relativ sicher, dass es nicht 30 oder 60 sein wird. Bei 47.4 ist das aber nicht ganz so klar. Vielleicht haben wir ja nur etwas Pech gehabt und liegen mit unserer Stichprobe eben etwas neben dem wahren Wert. Das Problem ist aber natürlich, dass wir den wahren Wert nicht kennen - wir kennen das Alter für alle Erwerbstätigen in Deutschland schlicht nicht. Da wir nun aber davon ausgehen müssen, dass wir mit unserer Stichprobe den exakten wahren Wert wohl nicht getroffen haben, geben wir ein Intervall innerhalb dessen wir den wahren Wert mit einigem Selbstbewusstsein verorten können. Dieses Intervall wird in der Regel als Konfidenzintervall bezeichnet. Aber wie bestimmen wir die Grenzen für dieses Intervall? Um die Grenzen sinnvoll zu bestimmen, benötigen wir eine Annahme wie sich der Stichprobenwert zum wahren Wert in der Grundgesamtheit verhält. &gt; Übrigens: Stichprobenmittelwerte werden häufig mit \\(\\bar{x}\\) bezeichnet, wohingegen der wahre Mittelwert in der Grundgesamtheit mit \\(\\mu\\) bezeichnet wird. &gt; Also: lateinischer Buchstabe für die Stichprobe, griechischer für die Grundgesamtheit. &gt; Für eine Schätzung von \\(\\mu\\) auf Basis eines Stichprobenwerts wird \\(\\hat{x}\\) verwendet (Dach). Wie kommen wir also von \\(\\bar{x}\\) zu \\(\\mu\\) oder zumindest zu \\(\\hat{x}\\)? Wie viel Schwankungsbreite sollten wir ansetzen? Dabei hilft uns die Streuung in der Stichprobe: wenn die Werte in der Stichprobe alle sehr nahe beieinander liegen, dann liegt es nahe, dass auch die Streuung in der Grundgesamtheit eher gering ist. Dementsprechend kann das Intervall um unsere Schätzung eher eng sein. Sollten wir beispielsweise im Extremfall 22000 identische Angaben im Datensatz haben, dann ist unser Selbstbewusstsein natürlich sehr viel kleiner als für Werte, die sehr weit auseinander liegen (= mit einer großen Varianz). Außerdem sind wir bei einer größeren Stichprobe vielleicht etwas sicherer als bei einer kleineren Datenbasis. Die Fallzahl sollte also auch berücksichtigt werden. Diese Überlegungen sind in folgender Formel eingebaut: \\[\\bar{x}\\,\\pm\\,t\\times\\frac{s}{\\sqrt{n}}\\] Wir bestimmen also auf Basis einer Stichprobe das Konfidenzintervall einer Schätzung, indem wir um den Punktschätzer (den Stichproben-Mittelwert, also die 47.19228 Jahre) mit Hilfe des eines geeigneten \\(t\\)-Werts und des Standardfehlers (\\(\\frac{s}{\\sqrt{n}}\\)1) einen Wertebereich um den Mittelwert \\(\\bar{x}\\) konstruieren. Das \\(t\\) kommt dabei aus der Student-t-Verteilung bzw. als \\(z\\)-Wert aus der Standard-Normalverteilung (Illustration). \\(t\\) wählen wir dabei so, dass bei wiederholter Stichprobenziehung 95% der resultierenden KI den wahren Wert aus der Grundgesamtheit beinhalten würden: Die t-Werte sind allerdings nicht fix, sondern hängen von der Stichprobengröße ab, mit invttail( n-1, .025) bekommen wir bspw. den t-Wert für das 95%-Konfidenzintervall: \\(n = 3\\) display invttail( 3-1, .025) = 4.3026527 \\(n = 30\\) display invttail( 30-1, .025) = 2.0452296 \\(n = 300\\) display invttail( 300-1, .025) = 1.9679297 \\(n = 3000\\) display invttail( 3000-1, .025) = 1.9607553 \\(n = 19836\\) display invttail( 19836-1, .025) = 1.9600836 Also würden für das 95%-Konfidenzintervall folgendes einsetzen - zur Erinnerung die Formel: \\[\\bar{x}\\,\\pm\\,t\\times\\frac{s}{\\sqrt{n}}\\] dis 47.19228 + 1.960084* 11.33762 / sqrt(19836) // obere Grenze 47.350066 dis 47.19228 - 1.960084* 11.33762 / sqrt(19836) // untere Grenze 47.034494 Aber nicht erschrecken - das macht alles Stata für uns: mean zpalter Mean estimation Number of obs = 19,836 -------------------------------------------------------------- | Mean Std. Err. [95% Conf. Interval] -------------+------------------------------------------------ zpalter | 47.19228 .0804998 47.03449 47.35006 -------------------------------------------------------------- 8.2 Hypothesentests Vergangene Session hatten wir aus Stichproben Aussagen über Parameter in einer Grundgesamtheit getroffen. Eigentliches Ziel statistischer Auswertungen ist aber häufig, Entscheidungen über allgemeine Hypothesen zu treffen. Ausgangsszenario: wir betrachten ein Merkmal und möchten durch eine Stichprobe überprüfen, ob der Mittelwert mit unserer Vermutung übereinstimmt bzw. größer/kleiner ist. Testen wir auf Übereinstimmung, verwenden wir einen sog. beidseitigen Test, bei einem einseitigen Test testen wir ob der Stichprobenwert signifikant größer bzw. kleiner als der vermutete Populationswert ist. Auch hier bleiben wir beim Durchschnittsalter der Erwerbstätigen - mit welcher Sicherheit können wir ausschließen, dass das Durchschnittsalter 47.4 Jahre ist? Wie wir eben gesehen haben, sollten wir uns nicht allein auf den Punktschätzer verlassen, sondern auch die Streuung in der Stichprobe mitberücksichtigen. Dies leisten die Hypothesentests. Dabei werden immer zwei sich widersprechende Hypothesen formuliert, die sog. \\(H_0\\) - die Nullhypothese und die \\(H_A\\) - die Alternativhypothese. Die \\(H_0\\) beschreibt dabei immer den bisherigen Kenntnisstand und die \\(H_A\\) formuliert die zu testende Aussage. Die Hypothesen unterscheiden sich dann je nachdem ob wir einen gerichteten oder einen ungerichteten Test durchführen: Zunächst müssen wir uns entscheiden ob wir eine gerichtete oder ungerichtete Hypothese testen möchten: ungerichtete Hypothese: das wahre Durchschnittsalter der Erwerbstätigen in D ist ungleich 47.4 Jahre gerichtete Hypothese: das wahre Durchschnittsalter der Erwerbstätigen in D ist kleiner/größer als 47.4 Jahre Formal werden die Hypothesen dann wie folgt festgehalten: ungerichtete Hypothesen: \\(H_0: \\mu = 47.4 Jahre\\) und \\(H_A: \\mu \\neq 47.4 Jahre\\) gerichtete Hypothesen: rechtsseitig \\(H_0: \\mu \\leqslant 47.4 Jahre\\) und \\(H_A: \\mu &gt; 47.4 Jahre\\) \\(\\Rightarrow\\) die \\(H_A\\) hält fest, dass der wahre Wert größer als der Wert aus der \\(H_0\\) ist linksseitig \\(H_0: \\mu \\geqslant 47.4 Jahre\\) und \\(H_A: \\mu &lt; 47.4 Jahre\\) \\(\\Rightarrow\\) die \\(H_A\\) hält fest, dass der wahre Wert kleiner als der Wert aus der \\(H_0\\) ist Die grundlegende Idee des Hypothesentests ist, dass wir uns nur dann für die Alternativhypothese entscheiden, wenn wir eine ausreichend große Abweichung von dem in der \\(H_0\\) postulierten Wert feststellen. Dazu berechnen wir den \\(t\\)-Wert für den SP-Mittelwert entsprechend dieser Formel: \\[t = \\frac{\\bar{x}-\\mu_{0}}{\\frac{\\sigma}{\\sqrt{n}}} = \\frac{\\bar{x}-\\mu_{0}}{\\frac{s_{x}}{\\sqrt{n}}}\\] Wir berechnen also, mit welcher Irrtumswahrscheinlichkeit wir die \\(H_0\\) verwerfen können. Anders formuliert: wie wahrscheinlich ist es, das \\(\\bar{x}\\) in einer Stichprobe zu erhalten obwohl \\(\\mu_0\\) in der Grundgesamtheit richtig ist? In der Wissenschaft hat sich als Konvention etabliert, von einem signifikanten Unterschied zu sprechen wenn die Irrtumswahrscheinlichkeit unter 5% liegt. Das bedeutet: Assuming that the null hypothesis is true and the study is repeated an infinite number times by drawing random samples from the same populations(s), less than 5% of these results will be more extreme than the current result.2 8.2.1 beiseitiger t-Test Ein beidseitiger Test testet die \\(H_0\\) im Vergleich zur folgenden Aussage der \\(H_A\\): die wahren Mietausgaben der Studierenden in Oldenburg sind ungleich 47.4 Jahre. Dazu formalisieren wir zunächst die \\(H_0\\) und \\(H_A\\): \\(H_0: \\mu = 47.4 Jahre \\qquad H_A: \\mu \\neq 47.4 Jahre\\) Für die Berechnung können wir in Stata die Funktion ttest nutzen. Neben den zu testenden Werten geben wir mit mu den in der Nullhypothese festgehaltenen Mittelwert an: ttest zpalter==47.4 One-sample t test ------------------------------------------------------------------------------ Variable | Obs Mean Std. Err. Std. Dev. [95% Conf. Interval] ---------+-------------------------------------------------------------------- zpalter | 19,836 47.19228 .0804998 11.33762 47.03449 47.35006 ------------------------------------------------------------------------------ mean = mean(zpalter) t = -2.5804 Ho: mean = 47.4 degrees of freedom = 19835 Ha: mean &lt; 47.4 Ha: mean != 47.4 Ha: mean &gt; 47.4 Pr(T &lt; t) = 0.0049 Pr(|T| &gt; |t|) = 0.0099 Pr(T &gt; t) = 0.9951 Das Ergebnis liegt also deutlich unter 0,05. Wir würden also die \\(H_0\\) verwerfen \\(\\Rightarrow\\) die Aussage das wahre Durchschnittsalter der Erwerbstätigen in D ist gleich 47.4 Jahre kann als (vorläufig) widerlegt gelten. Außerdem werden auch gleich die Ergebnisse für den linksseitigen und rechtsseitigen Test angezeigt. Diese sehen uns noch genauer an: 8.2.2 linksseitiger t-Test Ein linksseitiger Test testet die \\(H_0\\) im Vergleich zu folgender Aussage: das wahre Durchschnittsalter der Erwerbstätigen in D ist kleiner als 47.4 Jahre. Formal sehen die \\(H_0\\) und \\(H_A\\) so aus: \\(H_0:\\, \\mu \\geqslant 47.4 Jahre \\qquad H_A:\\, \\mu &lt; 47.4 Jahre\\) ttest zpalter==47.4 One-sample t test ------------------------------------------------------------------------------ Variable | Obs Mean Std. Err. Std. Dev. [95% Conf. Interval] ---------+-------------------------------------------------------------------- zpalter | 19,836 47.19228 .0804998 11.33762 47.03449 47.35006 ------------------------------------------------------------------------------ mean = mean(zpalter) t = -2.5804 Ho: mean = 47.4 degrees of freedom = 19835 Ha: mean &lt; 47.4 Ha: mean != 47.4 Ha: mean &gt; 47.4 Pr(T &lt; t) = 0.0049 Pr(|T| &gt; |t|) = 0.0099 Pr(T &gt; t) = 0.9951 Der Wert unter mean &lt; 47.4 ist mit 0.0049 kleiner als 0,05, dementsprechend würden wir auf Basis eines linksseitigen Hypothesentests die \\(H_0\\) verwerfen. 8.2.3 rechtsseitiger t-Test Ein rechtsseitiger Test testet die \\(H_0\\) im Vergleich zu folgender Aussage: das wahre Durchschnittsalter der Erwerbstätigen in ist größer als 47.4 Jahre. Formal sehen die \\(H_0\\) und \\(H_A\\) so aus: \\(H_0: \\mu \\leqslant 47.4 Jahre \\qquad H_A: \\mu &gt; 47.4 Jahre\\) ttest zpalter==47.4 One-sample t test ------------------------------------------------------------------------------ Variable | Obs Mean Std. Err. Std. Dev. [95% Conf. Interval] ---------+-------------------------------------------------------------------- zpalter | 19,836 47.19228 .0804998 11.33762 47.03449 47.35006 ------------------------------------------------------------------------------ mean = mean(zpalter) t = -2.5804 Ho: mean = 47.4 degrees of freedom = 19835 Ha: mean &lt; 47.4 Ha: mean != 47.4 Ha: mean &gt; 47.4 Pr(T &lt; t) = 0.0049 Pr(|T| &gt; |t|) = 0.0099 Pr(T &gt; t) = 0.9951 Wir sehen unter mean &gt; 47.4 dass der Wert 1-pt(q = -z_wert, df = 19836)=0.9951 deutlich größer als 0,05 ist - dementsprechend würden wir auf Basis eines rechtsseitigen Hypothesentests die \\(H_0\\) nicht verwerfen. All das haben wir eben auch schon in ttest gesehen: Übung 1 8.3 Mittelwertvergleiche mit dem t-Test Diese Testlogik können wir auch dazu verwenden, Kennzahlen für verschiedene Gruppen zu vergleichen. 8.3.1 Unverbundener t-Test Eine häufige Frage zielt darauf ab zu analysieren, ob sich die Durchschnittswerte eines Merkmals zwischen zwei Gruppen unterscheiden. Beispielsweise könnten wir das Durchschnittsalter zwischen erwerbstätigen Männern und Frauen vergleichen. Auch für Gruppenvergleich müssen zunächst Hypothesen aufgestellt werden. Für einen beidseitigen Test ist die Alternativhypothese, dass es einen Gruppenunterschied gibt: \\(H_0: \\mu_1 - \\mu_2 = 0 \\qquad H_A: \\mu_1 - \\mu_2 \\neq 0\\) Ein linksseitiger Test hätte entsprechend die Alternativhypothese, dass der Gruppenunterschied kleiner als 0 ist: \\(H_0: \\mu_1 - \\mu_2 \\geqslant 0 \\qquad H_A: \\mu_1 - \\mu_2 &lt; 0\\) Ein rechtssseitiger Test hätte entsprechend die Alternativhypothese, dass der Gruppenunterschied größer als 0 ist: \\(H_0: \\mu_1 - \\mu_2 \\leqslant 0 \\qquad H_A: \\mu_1 - \\mu_2 &gt; 0\\) Für den Altersvergleich zwischen Frauen und Männern ergeben sich folgende Hypothesen: ungerichtete Hypothese: \\(H_0: Alter_{m} - Alter_{f} = 0 \\qquad H_A: Alter_{m} - Alter_{f} \\neq 0\\) linksseitige Hypothese: \\(H_0: Alter_{m} - Alter_{f} \\geqslant 0 \\qquad H_A: Alter_{m} - Alter_{f} &lt; 0\\) rechtsseitige Hypothese: \\(H_0: Alter_{m} - Alter_{f} \\leqslant 0 \\qquad H_A: Alter_{m} - Alter_{f} &gt; 0\\) Wenn wir nun die beiden Mittelwerte für Männer und Frauen vergleichen, bezieht sich das natürlich wieder nur auf die Punktschätzer für die Stichprobe: tabstat zpalter,s(mean) by(S1) Summary for variables: zpalter by categories of: S1 (Geschlecht) S1 | mean ---------+---------- mÃ¤nnlich | 46.49079 weiblich | 47.90402 ---------+---------- Total | 47.19228 -------------------- Aber ist diese, in der Stichprobe festgestellte Differenz auch bezogen auf die Grundgesamtheit von Bedeutung? Dazu greifen wieder auf den ttest zurück, aber hier geben wir anstelle von == XYZ mit by(sex) die Gruppenvariable an: ttest zpalter, by(S1) unequal Two-sample t test with unequal variances ------------------------------------------------------------------------------ Group | Obs Mean Std. Err. Std. Dev. [95% Conf. Interval] ---------+-------------------------------------------------------------------- mÃ¤nnlich | 9,990 46.49079 .1188339 11.87744 46.25785 46.72373 weiblich | 9,846 47.90402 .1079952 10.71604 47.69233 48.11571 ---------+-------------------------------------------------------------------- combined | 19,836 47.19228 .0804998 11.33762 47.03449 47.35006 ---------+-------------------------------------------------------------------- diff | -1.413231 .1605754 -1.727972 -1.09849 ------------------------------------------------------------------------------ diff = mean(mÃ¤nnlich) - mean(weiblich) t = -8.8010 Ho: diff = 0 Satterthwaite&#39;s degrees of freedom = 19681.3 Ha: diff &lt; 0 Ha: diff != 0 Ha: diff &gt; 0 Pr(T &lt; t) = 0.0000 Pr(|T| &gt; |t|) = 0.0000 Pr(T &gt; t) = 1.0000 Da der p-Wert für den beiseitigen Test (unter Ha: diff != 0) deutlich unter 0,05 liegt, können wir hier die \\(H_0\\) verwerfen und gehen von signifikanten Größenunterschieden aus. Für einen rechtsseitigen Test achten wir auf Ha: diff &gt; 0- Männer sind also signifikant größer als Frauen. Für einen linksseitigen Test ist hingegen Ha: diff &lt; 0 ausschlaggebend: Männer sind also nicht signifikant kleiner als Frauen. Übung2 8.3.2 Verbundener t-Test Möchten wir Werte vergleichen, welche in einer Verbindung zueinander stehen, ist der verbundene t-Test die richtige Wahl. Beispiele für verbundene Stichproben sind beispielsweise experimentelle Untersuchungen, welche Daten vor und nach einer Maßnahme/Treatment/Intervention messen. Anschließend soll anhand des Vergleichs der Ergebnisse und die Wirkung der Maßnahme evaluiert werden. Hier sind die Messwerte aus den beiden Gruppen (vorher und nachher) miteinander verbunden - bspw. wird eine Person mit Bluthochdruck auch nach der Maßnahme in der Tendenz einen höheren Blutdruck haben als eine Person, welche bereits zuvor einen niedrigeren Blutdruck hatte. Ein fiktionales Beispiel: webuse bpwide browse bp_before bp_after Error in knitr::include_graphics(&quot;08_bpwide.png&quot;): Cannot find the file(s): &quot;08_bpwide.png&quot; Diese vorher/nachher Werte können wir jetzt mit einem verbundenen t-Test vergleichen: ttest bp_before==bp_after Paired t test ------------------------------------------------------------------------------ Variable | Obs Mean Std. Err. Std. Dev. [95% Conf. Interval] ---------+-------------------------------------------------------------------- bp_bef~e | 120 156.45 1.039746 11.38985 154.3912 158.5088 bp_after | 120 151.3583 1.294234 14.17762 148.7956 153.921 ---------+-------------------------------------------------------------------- diff | 120 5.091667 1.525736 16.7136 2.070557 8.112776 ------------------------------------------------------------------------------ mean(diff) = mean(bp_before - bp_after) t = 3.3372 Ho: mean(diff) = 0 degrees of freedom = 119 Ha: mean(diff) &lt; 0 Ha: mean(diff) != 0 Ha: mean(diff) &gt; 0 Pr(T &lt; t) = 0.9994 Pr(|T| &gt; |t|) = 0.0011 Pr(T &gt; t) = 0.0006 Auch hier sehen wir wieder die Ergebnisse für einen links- (Ha: mean(diff) &lt; 0) beid- (Ha: mean(diff) != 0) und rechtsseitigen (Ha: mean(diff) &gt; 0) Test. Wir erkennen aus den Ergebnissen, dass der Blutdruck der Patient*innen: nach dem Treatment nicht signifikant höher ist - linksseitiger Test (bp_before &lt; bp_after), linke Spalte sich vor und nach dem Treatment signifikant unterscheidet - beiseitiger Test (bp_before != bp_after), mittlere Spalte nach dem Treatment signifikant niedriger ist - rechtsseitiger Test (bp_before &gt; bp_after), rechte Spalte Übung3 8.4 Übersicht zu Varianten für ttest Für alle ttest-Varianten können wir mit , level(..) auch ein anderes Signifikanzniveau wählen. Standardmäßig wird \\(\\alpha=0,05\\%\\) verwendet. Vergleich zu einem Referenzwert: ttest testvariable == referenzwert Für Mittelwertvergleich gibt es insgesamt zwei Aspekte, anhand derer sich t-Tests unterscheiden: Die Varianz der Messwerte in den verglichenen Gruppen ist  gleich: \\(\\Rightarrow\\) ttest testvariable, by(gruppenvariable) verschieden: \\(\\Rightarrow\\) ttest testvariable, by(gruppenvariable) unequal (wie oben) Verbundene oder unverbundene Stichprobe? Sind die einzelnen Messwerte voneinander unabhängig? D.h. ein Messwert steht in keinem direkten Zusammenhang mit einem anderen \\(\\Rightarrow\\) ttest testvariable, by(gruppenvariable) für eine unverbundene Stichprobe (mit ggf. unequal) Stehen die einzelnen Messwerte in einem Zusammenhang? D.h. ein Messwert steht in einem direkten Zusammenhang mit einem anderen \\(\\Rightarrow\\) Werte für beide Variablen sollten nebeneinander abgelegt sein (wide-Format), dann kann mit ttest vorher==nachher ein verbundener ttest durchgeführt werden. 8.5 Gewichtung in Stata Wir können Gewichtungen in Stata auf zwei Weisen anwenden: Zum einen können die Daten mit dem Befehl svyset als Surveydaten definiert werden. Hierbei können Variablen spezifiziert werden, die Informationen über das Survey-Design enthalten, wie die Stratifizierung und die anzuwendende Gewichtungsvariable. Anschließende Analyseverfahren werden mit dem Befehlspräfix svy durchgeführt. In diesem Beispiel: tabulate S1 // ungewichtet Geschlecht | Freq. Percent Cum. ------------+----------------------------------- mÃ¤nnlich | 10,074 50.34 50.34 weiblich | 9,938 49.66 100.00 ------------+----------------------------------- Total | 20,012 100.00 svyset _n [pweight=gew2018] svy: tabulate S1 , col count pweight: gew2018 VCE: linearized Single unit: missing Strata 1: &lt;one&gt; SU 1: &lt;observations&gt; FPC 1: &lt;zero&gt; (running tabulate on estimation sample) Number of strata = 1 Number of obs = 20,012 Number of PSUs = 20,012 Population size = 20,012.017 Design df = 20,011 ---------------------------------- Geschlech | t | count column ----------+----------------------- mÃ¤nnlich | 1.1e+04 .5468 weiblich | 9070 .4532 | Total | 2.0e+04 1 ---------------------------------- Key: count = weighted count column = column proportion Allerdings steht das svy-Präfix nicht für jeden Befehl zur Verfügung. Außerdem können kein weiteren Präfixe neben svy verwendet werden - beispielsweise by. Daher steht auch eine Alternative zur Verfügung, bei der wir die Gewichtung bei jedem Auswertungsschritt einzeln angeben. In unserem Beispiel also tabulate S1 [weight=gew2018] may not use noninteger frequency weights r(401); Allerdings akzeptiert Stata bei einigen Gewichtungsverfahren (z.B. Häufigkeitsgewichten frequency weights), keine Gewichtungswerte mit Nachkommastellen. Leider führt ein einfaches Auf- oder Abrunden führt aber häufig zu falschen Ergebnissen: tabulate S1 [weight=round(gew2018)] // runden führt zu Abweichung - Vergleich mit svy: Ergebnis (frequency weights assumed) Geschlecht | Freq. Percent Cum. ------------+----------------------------------- mÃ¤nnlich | 10,524 55.44 55.44 weiblich | 8,458 44.56 100.00 ------------+----------------------------------- Total | 18,982 100.00 Eine mögliche Lösung dieser Problematik ist es, zunächst die Gewichtungsvariable mit einer hohen Zahl (bspw.100 000) zu multiplizieren und anschließend auf ganze Werte zu runden: tabulate S1 [weight=round(gew2018*100 000)] Verteilungen sollten anschließend korrekt berechnet werden. Beim Bericht der Ergebnisse ist jedoch zu beachten, dass die zu Grunde liegende Fallzahl anschließend wieder korrigiert werden muss (also in diesem Beispiel durch 100 000 geteilt werden muss). 8.6 Übungen 6 Laden Sie den BIBB/BAuA Erwerbstätigenbefragung 2018 (BIBBBAuA_2018_suf1.dta). 8.7 Anhang 8.7.1 Student-t vs. Normalverteilung \\[\\text{Normalverteilung:}\\;\\mathcal{N}(\\mu,\\sigma)\\] \\[\\text{Student-t-Verteilung:}\\;\\;\\; t_n=\\frac{\\mathcal{N}(0,1)}{\\sqrt{\\frac{\\chi^{2}_{n}}{n}}}\\] Der wesentlich Punkt ist, dass die Normalverteilung voraussetzt, dass wir \\(\\sigma^2\\) kennen - die Varianz (Streuung) der Altersangaben in der Grundgesamtheit. Aber wir kennen \\(\\sigma^2\\) genauso wenig wie \\(\\mu\\), sondern nur die Stichprobenmittelwerte \\(\\bar{x}\\) und -varianz \\(s^2\\). Daher halten wir uns an die Student-t-Verteilung, die quasi eine etwas lockerere Normalverteilung ist bei unbekannter Populationsvarianz. Die Bedeutung der Normalverteilung ergibt sich daraus, dass wichtige statistische Maßzahlen, die man aus Stichproben berechnen kann, unter bestimmten Bedingungen normalverteilt sind. Literaturtipps: + S.133 ff., Kapitel 6 Zufallsstichproben und Schätzen in Diaz-Bone, R. (2019). Statistik für Soziologen (4. Auflage) + S.79 ff. Kapitel 6 Stichprobe und Grundgesamtheit in Bortz, J., &amp; Schuster, C. (2010). Statistik für Human- und Sozialwissenschaftler (7. Auflage) (ausführliche formale Beschreibung) Also die Standardabweichung (\\(s\\)) dividiert durch die Wurzel der Stichprobengröße (\\(n\\)) Failing Grade: 89% of Introduction-to-Psychology Textbooks That Define or Explain Statistical Significance Do So Incorrectly. Advances in Methods and Practices in Psychological Science, 2515245919858072. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
